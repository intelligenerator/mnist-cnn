{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mnist-cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a super basic Convolutional Neural Network(CNN) to classify MNIST handwritten digits! We'll be using pytorch to specify and train our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST Dataset\n",
    "\n",
    "We'll be using the MNIST dataset to train our CNN. It contains images of handwritten digits. Loading MNIST is trivial using torchvision.\n",
    "\n",
    "Before we can use the images to train the network, it's a best practice to normalize the images. The images are black-and-white, represented by values from [0, 1]. The transformation will bring the values in a range of [-1, 1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", download=True, train=True, transform=transform\n",
    ")\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", download=True, train=False, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing\n",
    "\n",
    "Let's visualize the dataset before actually using it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(npimg[:, :], cmap='gray_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "imgs, labels = next(dataiter)\n",
    "show_img(imgs[0].squeeze())\n",
    "print('Label: %i' % labels[0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Now we can at last define our CNN. It consists of:\n",
    "- two convolutional blocks to extract relevant features from the input image\n",
    "- three fully connected layers to process the extracted features and classify the digit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(10, 10, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(250, 120),\n",
    "            nn.Linear(120, 60),\n",
    "            nn.Linear(60, NUM_CLASSES)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "First we'll try setting up pytorch to use a CUDA-capable GPU. If no GPU is detected, our CNN will be trained on CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device \"%s\" for training' % dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create an instance of our network before moving it to our training device using the `.to()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = Net().to(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define our loss and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(neural_net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train our network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (imgs, labels) in enumerate(trainloader):\n",
    "        imgs = imgs.to(dev)\n",
    "        labels = labels.to(dev)\n",
    "\n",
    "        # Important!\n",
    "        # Clear accumulated gradients from previous iteration\n",
    "        # before backpropagating. \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y = neural_net(imgs)\n",
    "        loss = criterion(y, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%.3d / %.3d] Loss: %.9f' % (epoch, i, running_loss / 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Finally, let's test the performance of our network on the testset, containing images of digits the network hasn't seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net.train(False)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        images, labels = data\n",
    "        images = images.to(dev)\n",
    "        labels = labels.to(dev)\n",
    "        \n",
    "        outputs = neural_net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
